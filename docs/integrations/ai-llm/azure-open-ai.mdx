---
slug: "/integrations/ai-llm/azure-open-ai"
description: "Learn how to integrate Azure OpenAI with your Orkes Conductor cluster."
---

# Integrating with Azure OpenAI in Orkes Conductor

To effectively utilize AI and LLM tasks in Orkes Conductor, it's essential to integrate your Orkes Conductor cluster with the necessary AI and LLM models. 

Azure OpenAI offers a range of models that can be incorporated into the Orkes Conductor cluster. The choice of model depends on your unique use case, the functionalities you require, and the specific natural language processing tasks you intend to tackle. 

This guide will provide the steps for integrating the Azure OpenAI provider with Orkes Conductor.

## Steps to integrate with Azure OpenAI

Before beginning to integrate with Azure OpenAI, you need to generate the API key and get the endpoints from the Azure portal.

### Get the Azure OpenAI API keys & Endpoint

1. Navigate to the [Azure portal](https://portal.azure.com).
2. Create an account or sign up with your existing account.
3. Under the **Azure services** section, choose **Azure OpenAI**.
4. Go to your resource and navigate to **Resource Management > Keys and Endpoint**.

<p align="center"><img src="/content/img/get-azure-open-ai-api-key.png" alt="Get Azure OpenAI API Key" width="100%" height="auto"></img></p>

5. Copy the API keys. You can either use _KEY_ 1 or _KEY 2_ as the API Key. 
6. Copy the endpoint provided under the OpenAI section. An example endpoint is https://docs-test-001.openai.azure.com/.

## Integrating with Azure OpenAI as a model provider

Now, you have the API keys and endpoint. Letâ€™s integrate this with Orkes Conductor.

1. Navigate to **Integrations** from the left menu on your Orkes Conductor cluster.
2. Click **+New integration** button from the top-right corner.
3. Under the **AI / LLM** section, choose **Azure + OpenAI**. 
4. Click **+Add** and provide the following parameters:

<p align="center"><img src="/content/img/create-new-azure-open-ai-integration.png" alt="Create Azure Open AI Integration" width="70%" height="auto"></img></p>

| Parameters | Description |
| ---------- | ----------- | 
| Integration name | A name for the integration. |
| API Key | The API key copied previously. |
| Endpoint | The endpoint copied previously. |
| Description | A description of your integration. | 

5. You can toggle-on the **Active** button to activate the integration instantly.
6. Click **Save**.

## Adding Azure OpenAI models to the integration

Now, you have integrated your Conductor cluster with the Azure OpenAI provider. The next step is integrating with the specific models. 

Azure OpenAI has different models, such as text-davinci-003, text-embedding-ada-002, gpt-35-turbo and more. Each model is to be used for different use cases, such as text completion, generating embeddings, etc.

Depending on your use case, you must configure the required model within your Azure OpenAI configuration.

To add a new model to the Azure OpenAI integration:

1. Navigate to the integrations page and click the '+' button next to the integration created.

<p align="center"><img src="/content/img/create-new-azure-open-ai-integration-model-from-integrations-page.png" alt="Create Azure Open AI Integration Model from Listed Integrations" width="100%" height="auto"></img></p>

2. Click **+New model**.
3. Provide the model name and an optional description for the model. The complete [list of models in Azure OpenAI is available here](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models). 

<p align="center"><img src="/content/img/create-new-azure-open-ai-integration-model.png" alt="Create Azure Open AI Integration Model" width="60%" height="auto"></img></p>

4. Toggle-on the **Active** button to enable the model immediately.
5. Click **Save**.

This ensures the integration model is saved for future use in LLM tasks within Orkes Conductor.

## RBAC - Governance on who can use Integrations

Now, the integration with the required models is ready. Next, we should determine the access control to these models. 

The permission can be granted to applications/groups within the Orkes Conductor cluster. 

To provide explicit permission to Groups:

1. Navigate to **Access Control > Groups** from the left menu on your Orkes Conductor cluster.
2. Create a new group or choose an existing group.
3. Under the **Permissions** section, click **+Add Permission**.
4. Under the **Integrations** tab, select the required integrations with the required permissions. 

<p align="center"><img src="/content/img/add-integration-permission.png" alt="Add Permissions for Integrations" width="70%" height="auto"></img></p>

5. Click **Add Permissions**. This ensures that all the group members can access these integration models in their workflows. 

Similarly, you can also provide permissions to [applications](https://orkes.io/content/access-control-and-security/applications#configuring-application). 

:::note
Once the integration is ready, [start creating workflows](https://orkes.io/content/reference-docs/api/metadata/creating-workflow-definition) with [LLM tasks](https://orkes.io/content/category/reference-docs/ai-tasks).
:::