---
sidebar_position: 5
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# LLM Get Embeddings

A system task to get the numerical vector representations of words, phrases, sentences, or documents that have been previously learned or generated by the model. Unlike the process of generating embeddings ([LLM Generate Embeddings](/content/reference-docs/ai-tasks/llm-generate-embeddings) task), which involves creating vector representations from input data, this task deals with the retrieval of pre-existing embeddings and uses them to search for data in vector databases. 

## Definitions

```json
{
"name": "llm_get_embeddings_task",
"taskReferenceName": "llm_get_embeddings_task_ref",
"inputParameters": {
"vectorDB": "pineconedb",
"namespace": "myNewModel",
"index": "test",
"embeddings": "${llm_generate_embeddings_task_ref.output}"
},
"type": "LLM_GET_EMBEDDINGS"
}
```

## Input Parameters

| Attribute | Description |
| --------- | ----------- | 
| vectorDB | Choose the required vector database.<br/><br/>**Note**:If you havenâ€™t configured the vector database on your Orkes console, navigate to the Integrations tab and configure your required provider. Refer to this doc on [how to integrate Vector Databases with Orkes console](/content/category/integrations/vector-databases). |
| namespace | Choose from the available namespace configured within the chosen vector database.<br/><br/>Namespaces are separate isolated environments within the database to manage and organize vector data effectively.<br/><br/>**Note**:Namespace field is applicable only for Pinecone integration and is not applicable to Weaviate integration.|
| index | Choose the index in your vector database where indexed text or data was stored.<br/><br/> **Note:**For Weaviate integration, this field refers to the class name, while in Pinecone integration, it denotes the index name itself.|
| embeddings | Choose the embeddings from which the stored data is to be retrieved. It needs to be from the same embedding model that was used to create the other embeddings that are stored in the same index. |

## Output Parameters

| Attribute | Description | 
| --------- | ----------- | 
| score | Represents a value that quantifies the degree of likeness between a specific item and a query vector, facilitating the ranking and ordering of results. Higher scores denote a stronger resemblance or relevance of a data point to the query vector.|
| docId | Displays the docId from where the text is queried.|

## Examples

<Tabs>
<TabItem value="UI" label="UI" className="paddedContent">

<div className="row">
<div className="col col--4">

<br/>
<br/>

1. Add task type **LLM Get Embeddings**.
2. Choose the vector database & namespace.
3. Provide the input parameters.

</div>
<div className="col">
<div className="embed-loom-video">

<p><img src="/content/img/llm-get-embeddings-ui-method.png" alt="LLM Get Embeddings Task" width="500" height="auto"/></p>

</div>
</div>
</div>



</TabItem>
 <TabItem value="JSON" label="JSON">

```json
{
"name": "llm_generate_embeddings_task",
"taskReferenceName": "llm_generate_embeddings_task_ref",
"inputParameters": {
"llmProvider": "azure_openai",
"model": "text-davinci-003",
"text": "${workflow.input.text}"
},
"type": "LLM_GENERATE_EMBEDDINGS"
},
{
"name": "llm_get_embeddings_task",
"taskReferenceName": "llm_get_embeddings_task_ref",
"inputParameters": {
"vectorDB": "pineconedb",
"namespace": "myNewModel",
"index": "test",
"embeddings": "${llm_generate_embeddings_task_ref.output}"
},
"type": "LLM_GET_EMBEDDINGS"
}
],
"inputParameters": [
"text"
]
```
</TabItem>
</Tabs>