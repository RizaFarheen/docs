---
sidebar_position: 8
slug: "/reference-docs/ai-tasks/llm-index-text"
description: "The LLM Index Text task indexes a provided text into a vector database."
---


import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# LLM Index Text

The LLM Index Text task is designed to index the provided text into a vector space for efficient search, retrieval, and processing at a later stage.

It takes text input, processes it using a specified language model to generate embeddings, and stores these embeddings in a chosen vector database. 

:::info Prerequisites

- [Integrate the required AI model](/category/integrations/ai-llm) with Orkes Conductor.
- [Integrate the required vector database](/category/integrations/vector-databases) with Orkes Conductor.
:::


## Task parameters

Configure these parameters for the LLM Index Text task.

| Parameter | Description | Required/ Optional | 
| --------- | ----------- | ----------------- |
| inputParameters.**vectorDB** | The vector database to store the data.<br/><br/>**Note**: If you haven’t configured the vector database on your Orkes Conductor cluster, navigate to the **Integrations** tab and [configure your required provider](/category/integrations/vector-databases). | Required. |
| inputParameters.**namespace** | Namespaces are separate isolated environments within the database to manage and organize vector data effectively. Choose from the available namespace configured within the chosen vector database.<br/><br/>The usage and terminology of the namespace field vary depending on the integration:<ul><li>For Pinecone, the namespace field is applicable.</li><li>For Weaviate, the namespace field is not applicable.</li><li>For MongoDB, the namespace field is referred to as “Collection” in MongoDB.</li><li>For Postgres, the namespace field is referred to as “Table” in Postgres.</li></ul> | Required. |
| inputParameters.**index** | The index in your vector database where the text or data will be stored.<br/><br/>The terminology of the index field varies depending on the integration:<ul><li>For Weaviate, the index field indicates the collection name.</li><li>For other integrations, it denotes the index name.</li></ul> | Required. | 
| inputParameters.**embeddingModelProvider** | The LLM provider for generating the embeddings.<br/><br/>**Note**: If you haven’t configured your AI/LLM provider on your Orkes console, navigate to the **Integrations** tab and [configure your required provider](/category/integrations/ai-llm). | Required. |
| inputParameters.**embeddingModel** | The embedding model provided by the selected LLM provider to generate the embeddings. | Required. |
| inputParameters.**text** | The text to be indexed. | Required. |
| inputParameters.**docId** | A unique ID to identify the document where the indexed text will be stored. | Optional. |
| inputParameters.**dimensions** | The size of the vector, which is the number of elements in the vector. | Optional. | 

The following are generic configuration parameters that can be applied to the task and are not specific to the LLM Index Text task.

<details>
<summary>Caching parameters</summary>

You can cache the task outputs using the following parameters. Refer to [Caching Task Outputs](/faqs/task-cache-output) for a full guide.

| Parameter | Description | Required/ Optional | 
| --------- | ----------- | ----------------- | 
| cacheConfig.**ttlInSecond** | The time to live in seconds, which is the duration for the output to be cached. | Required if using *cacheConfig*. |
| cacheConfig.**key** | The cache key is a unique identifier for the cached output and must be constructed exclusively from the task’s input parameters.<br/>It can be a string concatenation that contains the task’s input keys, such as `${uri}-${method}` or `re_${uri}_${method}`. | Required if using *cacheConfig*. |

</details>

<details>
<summary>Schema parameters</summary>

You can enforce input/output validation for the task using the following parameters. Refer to [Schema Validation](/developer-guides/schema-validation) for a full guide.

| Parameter | Description | Required/ Optional | 
| --------- | ----------- | ----------------- | 
| taskDefinition.**enforceSchema** | Whether to enforce schema validation for task inputs/outputs. Set to *true* to enable validation. | Optional. | 
| taskDefinition.**inputSchema** | The name and type of the input schema to be associated with the task. | Required if *enforceSchema* is set to true. | 
| taskDefinition.**outputSchema** | The name and type of the output schema to be associated with the task. | Required if *enforceSchema* is set to true.

</details>

<details>
<summary>Other generic parameters</summary>

Here are other parameters for configuring the task behavior.

| Parameter | Description | Required/ Optional | 
| --------- | ----------- | ----------------- | 
| optional | Whether the task is optional. The default is false. <br/> <br/> If set to true, the workflow continues to the next task even if this task is in progress or fails.| Optional. | 

</details>

## Task configuration

This is the task configuration for an LLM Index Text task.

```json
{
  "name": "llm_index_text_task",
  "taskReferenceName": "llm_index_text_task_ref",
  "inputParameters": {
    "vectorDB": "pineconedb",
    "namespace": "myNewModel",
    "index": "test",
    "embeddingModelProvider": "azure_openai",
    "embeddingModel": "text-davinci-003",
    "text": "${workflow.input.text}",
    "docId": "XXXX",
    "dimensions": "${workflow.input.dimensions}"
  },
  "type": "LLM_INDEX_TEXT"
}
```

## Task output

There is no output. The LLM Index Text task will store the indexed data in the specified vector database. 

## Adding an LLM Index Document task in UI

**To add an LLM Index Document task:**

1. In your workflow, select the (+) icon and add an **LLM Index Document** task.
2. Choose the **Vector database**, **Namespace**, **Index**, **Embedding model provider**, and **Embedding model**.
3. Enter the **Text** to be indexed.
4. (Optional) Enter an arbitrary **Doc ID** to store the indexed text.

<center><p><img src="/content/img/llm-index-text-ui-method.png" alt="LLM Index Text Task - UI" width="80%" height="auto"/></p></center>