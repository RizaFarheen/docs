---
slug: "/developer-guides/using-vector-databases-in-your-orkes-conductor-workflows"
description: "Learn how to use vector databases in Orkes' system LLM tasks, including the steps for integration and access control."
---

# Using Vector Databases

This guide provides an overview of vector databases and how Orkes Conductor makes it easy to use them for system AI tasks in workflows. 

:::tip
If you are already familiar with vector databases, skip the overview and proceed to the [configuration steps](/content/developer-guides/using-vector-databases-in-your-orkes-conductor-workflows#configuring-vector-databases).
:::

## Overview: Vector databases

A vector database is a type of database specifically designed to store and query vectors or multidimensional data. Vectors are mathematical entities with an ordered set of numerical values, often representing points or data in a multidimensional space.

### Embeddings

An embedding is a representation of input data converted into an array of numbers known as vectors. This combination of numbers represented as a vector acts as a multidimensional map that can be used to find its similarity to other embeddings. A language model typically generates embeddings from an input and stores them in a database.

### Namespaces

A namespace is a logical grouping or category of embeddings within a vector database. They are used to segregate different types of data or embeddings. It helps organize and manage diverse embeddings for more efficient storage and querying. 

### Indexes

Indexes are hierarchical structures built on embeddings in a vector database to optimize retrieval and query performance, similar to tables in a relational database. Each namespace can contain multiple indexes. Indexes help you quickly locate and retrieve embeddings based on their similarity to a given query vector. Vendors use different terminology—Pinecone refers to them as "indexes," while Weaviate calls them "collections."

## Configuring vector databases​

:::info Prerequisites
- An AI model generates an embedding to store data in a vector database. To facilitate this process, you must also integrate an [AI model provider](/content/category/integrations/ai-llm) of your choice.
:::

Here is an overview of using vector databases in Orkes Conductor:

1. Choose a vector database provider.
2. Integrate your chosen vector database with your Orkes Conductor cluster.
3. Set access limits to the vector database to govern which applications or groups can use it.
4. Use a vector database in your workflow by adding an AI task and configuring it for the chosen vector database.

## Step 1: Choose a vector database provider

The following vector database providers are available for integration with Orkes Conductor:

- [Pinecone](https://docs.pinecone.io/guides/get-started/overview)
- [Weaviate](https://weaviate.io/developers/weaviate)
- [Postgres Vector Database (pgvector)](https://github.com/pgvector/pgvector/)
- [Mongo Vector Database (MongoDB Atlas)](https://www.mongodb.com/docs/atlas/)

Review the provider’s official documentation to determine which database suits your use case.

## Step 2: Integrate a vector database provider

Before using a vector database in a workflow, you must integrate it with your Orkes Conductor cluster.

**To integrate a vector database provider:**

1. Go to **Integrations** from the left navigation menu on your Conductor cluster.
2. Select **+ New integration**.
3. In the **Vector Databases** section, select **+ Add** to integrate your preferred database provider.

<p align="center"><img src="/content/img/add-integrations-for-dbs.png" alt="Add New Integrations for Databases" width="100%" height="auto"></img></p>

4. Enter the required parameters for the chosen provider.

:::note
The integration configuration differs with each provider. For detailed steps on integrating with each provider, refer to [Vector Database Integrations](https://orkes.io/content/category/integrations/vector-databases).
:::

5. (Optional) Toggle the **Active** button off if you don’t want to activate the integration instantly.
6. Select **Save**.

### Add the preferred indexes/collections

Once the vector database integration is added, you can begin adding indexes/collections from the provider.

**To add an index/collection:**

1. In **Integrations**, select the + icon next to your newly-created integration.
2. For Pinecone, Postgres Vector Database, or Mongo Vector Database, select **+ New Index**.
3. For Weavite, select **+ New Collection**.
4. Enter the index/collectional name and an optional description. 
5. (Optional) Toggle the **Active** button off if you don’t want to activate it instantly.
6. Select **Save**.

## Step 3: Set access limit for integrations

As best practice, use Orkes’ [RBAC feature](https://orkes.io/content/category/access-control-and-security) to govern which user groups or applications can access the database providers.

**To provide access to an application or group:**

1. Go to **Access Control** > **Applications** or **Groups** from the left navigation menu on your Conductor cluster.
2. Create a new group/application or select an existing one.
3. In the **Permissions** section, select **+Add permission**.
4. In the **Integration** tab, select the required vector databases and toggle the necessary permissions.

<p align="center"><img src="/content/img/add-integration-permission-for-vector-db.png" alt="Add Permissions for Integrations with Vector Database" width="60%" height="auto"></img></p>

5. Select **Add Permissions**. 

The group or application can now access the vector databases according to the configured permissions.

## Step 4: Use vector databases in workflows

Vector databases can be used in workflows with the following system AI tasks:

- [LLM Get Embeddings](https://orkes.io/content/reference-docs/ai-tasks/llm-get-embeddings)
- [LLM Store Embeddings](https://orkes.io/content/reference-docs/ai-tasks/llm-store-embeddings)
- [LLM Search Index](https://orkes.io/content/reference-docs/ai-tasks/llm-search-index)
- [LLM Index Document](https://orkes.io/content/reference-docs/ai-tasks/llm-index-document)
- [LLM Index Text](https://orkes.io/content/reference-docs/ai-tasks/llm-index-text)

**To use a vector database in workflows:**

1. Go to **Definitions** > **Workflow** from the left navigation menu on your Conductor cluster.
2. Select **+ Define workflow**.
3. In the visual workflow editor, select **Start** and add the relevant AI task based on your use case.
4. Select the configured vector database and indexes.

<p align="center"><img src="/content/img/using-vector-database-in-workflow.png" alt="Using vector database integration in a Conductor workflow" width="90%" height="auto"></img></p>

5. Configure the remaining task parameters. 

:::note
Refer to the [AI Task Reference](https://orkes.io/content/category/reference-docs/ai-tasks) for more details on configuring the task parameters.
:::

6. Select **Save** > **Confirm**.

## More resources

- [Using AI Models or LLMs](https://orkes.io/content/developer-guides/using-llms-in-your-orkes-conductor-workflows)
- [Vector Database Integration Guides](https://orkes.io/content/category/integrations/vector-databases)
- [AI Task Reference](https://orkes.io/content/category/reference-docs/ai-tasks)
